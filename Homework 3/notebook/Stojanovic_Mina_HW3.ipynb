{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "**name:** Mina Stojanovic  \n",
    "**github id:** minastoj  \n",
    "**USC student id:** 4968308304  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "#### (c) Feature Extraction\n",
    "#### Classification of time series usually needs extracting features from them. In this problem, we focus on time-domain features.\n",
    "i. Research what types of time-domain features are usually used in time series classification and list them (examples are minimum, maximum, mean, etc).\n",
    "\n",
    "Common time-domain features that are used in time series classification include:\n",
    "- mean\n",
    "- median\n",
    "- standard deviation\n",
    "- variance\n",
    "- quartiles\n",
    "- interquartile range\n",
    "- minimum\n",
    "- maximum\n",
    "- zero-crossing rate\n",
    "- amplitude envelope\n",
    "- skewness\n",
    "- kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Extract the time-domain features minimum, maximum, mean, median, standard deviation, first quartile, and third quartile for all of the 6 time series in each instance. You are free to normalize/standardize features or use them directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Instance</th>\n",
       "      <th>min_1</th>\n",
       "      <th>max_1</th>\n",
       "      <th>mean_1</th>\n",
       "      <th>median_1</th>\n",
       "      <th>std_1</th>\n",
       "      <th>1st quart_1</th>\n",
       "      <th>3rd quart_1</th>\n",
       "      <th>min_2</th>\n",
       "      <th>max_2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_5</th>\n",
       "      <th>1st quart_5</th>\n",
       "      <th>3rd quart_5</th>\n",
       "      <th>min_6</th>\n",
       "      <th>max_6</th>\n",
       "      <th>mean_6</th>\n",
       "      <th>median_6</th>\n",
       "      <th>std_6</th>\n",
       "      <th>1st quart_6</th>\n",
       "      <th>3rd quart_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>36.25</td>\n",
       "      <td>48.00</td>\n",
       "      <td>43.969125</td>\n",
       "      <td>44.500</td>\n",
       "      <td>1.618364</td>\n",
       "      <td>43.31</td>\n",
       "      <td>44.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3.318301</td>\n",
       "      <td>20.5000</td>\n",
       "      <td>23.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.555313</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.487826</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>37.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>43.454958</td>\n",
       "      <td>43.250</td>\n",
       "      <td>1.386098</td>\n",
       "      <td>42.50</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>...</td>\n",
       "      <td>2.488862</td>\n",
       "      <td>22.2500</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.26</td>\n",
       "      <td>0.679646</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.622534</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.8700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>33.00</td>\n",
       "      <td>47.75</td>\n",
       "      <td>42.179813</td>\n",
       "      <td>43.500</td>\n",
       "      <td>3.670666</td>\n",
       "      <td>39.15</td>\n",
       "      <td>45.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.849448</td>\n",
       "      <td>30.4575</td>\n",
       "      <td>36.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.613521</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.524317</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>33.00</td>\n",
       "      <td>45.75</td>\n",
       "      <td>41.678063</td>\n",
       "      <td>41.750</td>\n",
       "      <td>2.243490</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>...</td>\n",
       "      <td>2.411026</td>\n",
       "      <td>28.4575</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.383292</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.389164</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>37.25</td>\n",
       "      <td>45.00</td>\n",
       "      <td>40.624792</td>\n",
       "      <td>40.500</td>\n",
       "      <td>1.476967</td>\n",
       "      <td>39.25</td>\n",
       "      <td>42.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188449</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.570583</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>19.75</td>\n",
       "      <td>45.50</td>\n",
       "      <td>34.322750</td>\n",
       "      <td>35.250</td>\n",
       "      <td>4.752477</td>\n",
       "      <td>31.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.47</td>\n",
       "      <td>...</td>\n",
       "      <td>3.119856</td>\n",
       "      <td>13.5000</td>\n",
       "      <td>17.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.67</td>\n",
       "      <td>3.432562</td>\n",
       "      <td>3.200</td>\n",
       "      <td>1.732727</td>\n",
       "      <td>2.1575</td>\n",
       "      <td>4.5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>85</td>\n",
       "      <td>19.25</td>\n",
       "      <td>44.00</td>\n",
       "      <td>34.473188</td>\n",
       "      <td>35.000</td>\n",
       "      <td>4.796705</td>\n",
       "      <td>31.25</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.86</td>\n",
       "      <td>...</td>\n",
       "      <td>3.156320</td>\n",
       "      <td>13.7300</td>\n",
       "      <td>17.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.00</td>\n",
       "      <td>3.340458</td>\n",
       "      <td>3.090</td>\n",
       "      <td>1.699114</td>\n",
       "      <td>2.1200</td>\n",
       "      <td>4.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>86</td>\n",
       "      <td>23.50</td>\n",
       "      <td>46.25</td>\n",
       "      <td>34.873229</td>\n",
       "      <td>35.250</td>\n",
       "      <td>4.531720</td>\n",
       "      <td>31.75</td>\n",
       "      <td>38.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.82</td>\n",
       "      <td>...</td>\n",
       "      <td>3.131076</td>\n",
       "      <td>13.7500</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.51</td>\n",
       "      <td>3.424646</td>\n",
       "      <td>3.270</td>\n",
       "      <td>1.690960</td>\n",
       "      <td>2.1700</td>\n",
       "      <td>4.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>87</td>\n",
       "      <td>18.33</td>\n",
       "      <td>45.75</td>\n",
       "      <td>34.599875</td>\n",
       "      <td>35.125</td>\n",
       "      <td>4.731790</td>\n",
       "      <td>31.50</td>\n",
       "      <td>38.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.37</td>\n",
       "      <td>...</td>\n",
       "      <td>2.905688</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.86</td>\n",
       "      <td>3.289542</td>\n",
       "      <td>3.015</td>\n",
       "      <td>1.680170</td>\n",
       "      <td>2.1200</td>\n",
       "      <td>4.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>15.50</td>\n",
       "      <td>43.67</td>\n",
       "      <td>34.225875</td>\n",
       "      <td>34.750</td>\n",
       "      <td>4.441798</td>\n",
       "      <td>31.25</td>\n",
       "      <td>37.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.24</td>\n",
       "      <td>...</td>\n",
       "      <td>2.992920</td>\n",
       "      <td>14.3300</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.42</td>\n",
       "      <td>3.479542</td>\n",
       "      <td>3.270</td>\n",
       "      <td>1.761146</td>\n",
       "      <td>2.2400</td>\n",
       "      <td>4.5375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Instance  min_1  max_1     mean_1  median_1     std_1  1st quart_1  \\\n",
       "0          1  36.25  48.00  43.969125    44.500  1.618364        43.31   \n",
       "1          2  37.00  48.00  43.454958    43.250  1.386098        42.50   \n",
       "2          3  33.00  47.75  42.179813    43.500  3.670666        39.15   \n",
       "3          4  33.00  45.75  41.678063    41.750  2.243490        41.33   \n",
       "4          5  37.25  45.00  40.624792    40.500  1.476967        39.25   \n",
       "..       ...    ...    ...        ...       ...       ...          ...   \n",
       "83        84  19.75  45.50  34.322750    35.250  4.752477        31.00   \n",
       "84        85  19.25  44.00  34.473188    35.000  4.796705        31.25   \n",
       "85        86  23.50  46.25  34.873229    35.250  4.531720        31.75   \n",
       "86        87  18.33  45.75  34.599875    35.125  4.731790        31.50   \n",
       "87        88  15.50  43.67  34.225875    34.750  4.441798        31.25   \n",
       "\n",
       "    3rd quart_1  min_2  max_2  ...     std_5  1st quart_5  3rd quart_5  min_6  \\\n",
       "0         44.67    0.0   1.50  ...  3.318301      20.5000        23.75   0.00   \n",
       "1         45.00    0.0   1.58  ...  2.488862      22.2500        24.00   0.00   \n",
       "2         45.00    0.0   3.00  ...  3.849448      30.4575        36.33   0.00   \n",
       "3         42.75    0.0   2.83  ...  2.411026      28.4575        31.25   0.00   \n",
       "4         42.00    0.0   1.30  ...  2.188449      33.0000        36.00   0.00   \n",
       "..          ...    ...    ...  ...       ...          ...          ...    ...   \n",
       "83        38.00    0.0  13.47  ...  3.119856      13.5000        17.75   0.00   \n",
       "84        38.00    0.0  13.86  ...  3.156320      13.7300        17.75   0.43   \n",
       "85        38.25    0.0  14.82  ...  3.131076      13.7500        18.00   0.00   \n",
       "86        38.00    0.0  15.37  ...  2.905688      14.0000        18.25   0.00   \n",
       "87        37.25    0.0  17.24  ...  2.992920      14.3300        18.25   0.00   \n",
       "\n",
       "    max_6    mean_6  median_6     std_6  1st quart_6  3rd quart_6  \n",
       "0    2.96  0.555313     0.490  0.487826       0.0000       0.8300  \n",
       "1    5.26  0.679646     0.500  0.622534       0.4300       0.8700  \n",
       "2    2.18  0.613521     0.500  0.524317       0.0000       1.0000  \n",
       "3    1.79  0.383292     0.430  0.389164       0.0000       0.5000  \n",
       "4    1.92  0.570583     0.430  0.582915       0.0000       1.3000  \n",
       "..    ...       ...       ...       ...          ...          ...  \n",
       "83   9.67  3.432562     3.200  1.732727       2.1575       4.5650  \n",
       "84   9.00  3.340458     3.090  1.699114       2.1200       4.3750  \n",
       "85   9.51  3.424646     3.270  1.690960       2.1700       4.5000  \n",
       "86   8.86  3.289542     3.015  1.680170       2.1200       4.2600  \n",
       "87   9.42  3.479542     3.270  1.761146       2.2400       4.5375  \n",
       "\n",
       "[88 rows x 43 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# returns minimum, maximum, mean, median, standard deviation, first quartile, and third quartile of each trait\n",
    "def get_features(df, file_num):\n",
    "    features = [file_num]\n",
    "\n",
    "    for column in df.columns:\n",
    "        min_val = df[column].min()\n",
    "        max_val = df[column].max()\n",
    "        mean_val = df[column].mean()\n",
    "        median_val = df[column].median()\n",
    "        std_dev_val = df[column].std()\n",
    "        first_quartile = df[column].quantile(0.25)\n",
    "        third_quartile = df[column].quantile(0.75)\n",
    "\n",
    "        features.extend([min_val, max_val, mean_val, median_val, std_dev_val, first_quartile, third_quartile])\n",
    "\n",
    "    return features\n",
    "\n",
    "head_folder = \"../data/AReM/\" # + folder name / file name\n",
    "folder_names = ['bending1', 'bending2', 'cycling', 'lying', 'sitting', 'standing', 'walking']\n",
    "\n",
    "column_names = ['time', 'avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'vg_rss23', 'ar_rss23']\n",
    "all_features = [] # to hold all mins/maxs/etc to eventually put into a dataframe\n",
    "file_num = 1\n",
    "\n",
    "# loop through files in each folder\n",
    "for name in folder_names:\n",
    "    curr_folder = head_folder + name + \"/\"\n",
    "\n",
    "    for file in os.listdir(curr_folder):\n",
    "        df = pd.read_csv(curr_folder + file, skiprows=5, names=column_names)\n",
    "        # edge case for a file in bending2\n",
    "        if df.isnull().values.any():\n",
    "            # read this file with whitespace as delimiter\n",
    "            df = pd.read_csv(curr_folder + file, skiprows=5, delim_whitespace=True, names=column_names)\n",
    "        df = df.drop(columns=['time'], axis=1) # don't need the \"time\" column\n",
    "        all_features.append(get_features(df, file_num))\n",
    "        file_num += 1\n",
    "\n",
    "# create table columns for each time series\n",
    "table_columns = ['Instance']\n",
    "for i in range(1, 7): # for 6 time series\n",
    "    table_columns.extend([f'min_{i}', f'max_{i}', f'mean_{i}', f'median_{i}', f'std_{i}', f'1st quart_{i}', f'3rd quart_{i}'])\n",
    "\n",
    "table_df = pd.DataFrame(all_features, columns=table_columns)\n",
    "display(table_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Estimate the standard deviation of each of the time-domain features you extracted from the data. Then, use Python’s bootstrapped or any other method to build a 90% bootstrap confidence interval for the standard deviation of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standard Deviation</th>\n",
       "      <th>Lower Bound</th>\n",
       "      <th>Upper Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min_1</th>\n",
       "      <td>9.569975</td>\n",
       "      <td>8.208853</td>\n",
       "      <td>10.648443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_1</th>\n",
       "      <td>4.394362</td>\n",
       "      <td>3.319755</td>\n",
       "      <td>5.223690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_1</th>\n",
       "      <td>5.335718</td>\n",
       "      <td>4.672707</td>\n",
       "      <td>5.888579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_1</th>\n",
       "      <td>5.440054</td>\n",
       "      <td>4.752945</td>\n",
       "      <td>5.955532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_1</th>\n",
       "      <td>1.772153</td>\n",
       "      <td>1.564011</td>\n",
       "      <td>1.942343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st quart_1</th>\n",
       "      <td>6.153590</td>\n",
       "      <td>5.588508</td>\n",
       "      <td>6.561074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd quart_1</th>\n",
       "      <td>5.138925</td>\n",
       "      <td>4.287293</td>\n",
       "      <td>5.801758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_2</th>\n",
       "      <td>5.062729</td>\n",
       "      <td>4.623228</td>\n",
       "      <td>5.389188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_2</th>\n",
       "      <td>1.574164</td>\n",
       "      <td>1.390874</td>\n",
       "      <td>1.702116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_2</th>\n",
       "      <td>1.412244</td>\n",
       "      <td>1.236244</td>\n",
       "      <td>1.536818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_2</th>\n",
       "      <td>0.884105</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>0.934619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st quart_2</th>\n",
       "      <td>0.946386</td>\n",
       "      <td>0.822333</td>\n",
       "      <td>1.031678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd quart_2</th>\n",
       "      <td>2.125266</td>\n",
       "      <td>1.890229</td>\n",
       "      <td>2.279622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_3</th>\n",
       "      <td>2.956462</td>\n",
       "      <td>2.740036</td>\n",
       "      <td>3.082024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_3</th>\n",
       "      <td>4.875137</td>\n",
       "      <td>4.133354</td>\n",
       "      <td>5.427936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_3</th>\n",
       "      <td>4.008380</td>\n",
       "      <td>3.375572</td>\n",
       "      <td>4.449362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_3</th>\n",
       "      <td>4.036396</td>\n",
       "      <td>3.375068</td>\n",
       "      <td>4.553662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_3</th>\n",
       "      <td>0.946710</td>\n",
       "      <td>0.760262</td>\n",
       "      <td>1.105803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st quart_3</th>\n",
       "      <td>4.220658</td>\n",
       "      <td>3.619948</td>\n",
       "      <td>4.725135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd quart_3</th>\n",
       "      <td>4.171628</td>\n",
       "      <td>3.517265</td>\n",
       "      <td>4.660785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_4</th>\n",
       "      <td>2.183625</td>\n",
       "      <td>1.961331</td>\n",
       "      <td>2.353711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_4</th>\n",
       "      <td>1.166114</td>\n",
       "      <td>1.076880</td>\n",
       "      <td>1.217264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_4</th>\n",
       "      <td>1.145586</td>\n",
       "      <td>1.053955</td>\n",
       "      <td>1.196192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_4</th>\n",
       "      <td>0.458242</td>\n",
       "      <td>0.420600</td>\n",
       "      <td>0.482556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st quart_4</th>\n",
       "      <td>0.843620</td>\n",
       "      <td>0.766779</td>\n",
       "      <td>0.887590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd quart_4</th>\n",
       "      <td>1.552504</td>\n",
       "      <td>1.429486</td>\n",
       "      <td>1.618441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_5</th>\n",
       "      <td>6.124001</td>\n",
       "      <td>4.197546</td>\n",
       "      <td>7.538739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_5</th>\n",
       "      <td>5.741238</td>\n",
       "      <td>4.741502</td>\n",
       "      <td>6.516784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_5</th>\n",
       "      <td>5.675593</td>\n",
       "      <td>4.452661</td>\n",
       "      <td>6.718934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_5</th>\n",
       "      <td>5.813782</td>\n",
       "      <td>4.528280</td>\n",
       "      <td>6.903916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_5</th>\n",
       "      <td>1.024898</td>\n",
       "      <td>0.821447</td>\n",
       "      <td>1.203903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st quart_5</th>\n",
       "      <td>6.096465</td>\n",
       "      <td>4.860832</td>\n",
       "      <td>7.167330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd quart_5</th>\n",
       "      <td>5.531720</td>\n",
       "      <td>4.355206</td>\n",
       "      <td>6.539517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_6</th>\n",
       "      <td>0.045838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_6</th>\n",
       "      <td>2.518921</td>\n",
       "      <td>2.234783</td>\n",
       "      <td>2.712491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_6</th>\n",
       "      <td>1.154812</td>\n",
       "      <td>1.056381</td>\n",
       "      <td>1.210475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_6</th>\n",
       "      <td>1.086474</td>\n",
       "      <td>0.992410</td>\n",
       "      <td>1.146015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_6</th>\n",
       "      <td>0.517617</td>\n",
       "      <td>0.477609</td>\n",
       "      <td>0.542446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st quart_6</th>\n",
       "      <td>0.758584</td>\n",
       "      <td>0.687675</td>\n",
       "      <td>0.799998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd quart_6</th>\n",
       "      <td>1.523599</td>\n",
       "      <td>1.385582</td>\n",
       "      <td>1.591553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Standard Deviation  Lower Bound  Upper Bound\n",
       "min_1                  9.569975     8.208853    10.648443\n",
       "max_1                  4.394362     3.319755     5.223690\n",
       "mean_1                 5.335718     4.672707     5.888579\n",
       "median_1               5.440054     4.752945     5.955532\n",
       "std_1                  1.772153     1.564011     1.942343\n",
       "1st quart_1            6.153590     5.588508     6.561074\n",
       "3rd quart_1            5.138925     4.287293     5.801758\n",
       "min_2                  0.000000     0.000000     0.000000\n",
       "max_2                  5.062729     4.623228     5.389188\n",
       "mean_2                 1.574164     1.390874     1.702116\n",
       "median_2               1.412244     1.236244     1.536818\n",
       "std_2                  0.884105     0.794613     0.934619\n",
       "1st quart_2            0.946386     0.822333     1.031678\n",
       "3rd quart_2            2.125266     1.890229     2.279622\n",
       "min_3                  2.956462     2.740036     3.082024\n",
       "max_3                  4.875137     4.133354     5.427936\n",
       "mean_3                 4.008380     3.375572     4.449362\n",
       "median_3               4.036396     3.375068     4.553662\n",
       "std_3                  0.946710     0.760262     1.105803\n",
       "1st quart_3            4.220658     3.619948     4.725135\n",
       "3rd quart_3            4.171628     3.517265     4.660785\n",
       "min_4                  0.000000     0.000000     0.000000\n",
       "max_4                  2.183625     1.961331     2.353711\n",
       "mean_4                 1.166114     1.076880     1.217264\n",
       "median_4               1.145586     1.053955     1.196192\n",
       "std_4                  0.458242     0.420600     0.482556\n",
       "1st quart_4            0.843620     0.766779     0.887590\n",
       "3rd quart_4            1.552504     1.429486     1.618441\n",
       "min_5                  6.124001     4.197546     7.538739\n",
       "max_5                  5.741238     4.741502     6.516784\n",
       "mean_5                 5.675593     4.452661     6.718934\n",
       "median_5               5.813782     4.528280     6.903916\n",
       "std_5                  1.024898     0.821447     1.203903\n",
       "1st quart_5            6.096465     4.860832     7.167330\n",
       "3rd quart_5            5.531720     4.355206     6.539517\n",
       "min_6                  0.045838     0.000000     0.078029\n",
       "max_6                  2.518921     2.234783     2.712491\n",
       "mean_6                 1.154812     1.056381     1.210475\n",
       "median_6               1.086474     0.992410     1.146015\n",
       "std_6                  0.517617     0.477609     0.542446\n",
       "1st quart_6            0.758584     0.687675     0.799998\n",
       "3rd quart_6            1.523599     1.385582     1.591553"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# REFERENCE: Site #1\n",
    "# does bootstrap and calculates confidence intervals\n",
    "def bootstrap_ci(data, num_iterations=1000, confidence_level=0.90):\n",
    "    bootstrap_samples = np.random.choice(data, (num_iterations, len(data)), replace=True)\n",
    "    bootstrap_std_devs = np.std(bootstrap_samples, axis=1)\n",
    "\n",
    "    lower_bound = np.percentile(bootstrap_std_devs, (1 - confidence_level) / 2 * 100)\n",
    "    upper_bound = np.percentile(bootstrap_std_devs, (1 + confidence_level) / 2 * 100)\n",
    "\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "confidence_intervals = {}\n",
    "\n",
    "# calculate bootstrap confidence intervals for each feature\n",
    "for feature in table_df.columns[1:]:\n",
    "    lower_bound, upper_bound = bootstrap_ci(table_df[feature].values)\n",
    "    confidence_intervals[feature] = (lower_bound, upper_bound)\n",
    "\n",
    "# make dataframe for all confidence intervals\n",
    "confidence_intervals_df = pd.DataFrame(confidence_intervals, index=['Lower Bound', 'Upper Bound']).T\n",
    "\n",
    "std_devs = table_df.iloc[:, 1:].std() # standard devs of all features\n",
    "confidence_intervals_df['Standard Deviation'] = std_devs.values # add standard devs to df\n",
    "confidence_intervals_df = confidence_intervals_df[['Standard Deviation', 'Lower Bound', 'Upper Bound']] # rearrange columns\n",
    "\n",
    "display(confidence_intervals_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. Use your judgement to select the three most important time-domain features (one option may be min, mean, and max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.129335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3rd quart</th>\n",
       "      <td>3.340607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st quart</th>\n",
       "      <td>3.169884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Average Standard Deviation\n",
       "max                          4.129335\n",
       "3rd quart                    3.340607\n",
       "1st quart                    3.169884"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to their high standard deviations,  ['max' '3rd quart' '1st quart']  have the highest variability in the dataset.\n",
      "This means meaning they are able to differentiate between the classes the best and represent separation between classes.\n",
      "Thus, they are the most important time-domain features.\n"
     ]
    }
   ],
   "source": [
    "# get average of standard devs of time-domain features\n",
    "avg_min_std_dev = confidence_intervals_df[confidence_intervals_df.index.str.contains(\"min\")]['Standard Deviation'].mean()\n",
    "avg_max_std_dev = confidence_intervals_df[confidence_intervals_df.index.str.contains(\"max\")]['Standard Deviation'].mean()\n",
    "avg_mean_std_dev = confidence_intervals_df[confidence_intervals_df.index.str.contains(\"mean\")]['Standard Deviation'].mean()\n",
    "avg_median_std_dev = confidence_intervals_df[confidence_intervals_df.index.str.contains(\"median\")]['Standard Deviation'].mean()\n",
    "avg_std_std_dev = confidence_intervals_df[confidence_intervals_df.index.str.contains(\"std\")]['Standard Deviation'].mean()\n",
    "avg_1st_quart_std_dev = confidence_intervals_df[confidence_intervals_df.index.str.contains(\"1st quart\")]['Standard Deviation'].mean()\n",
    "avg_3rd_quart_std_dev = confidence_intervals_df[confidence_intervals_df.index.str.contains(\"3rd quart\")]['Standard Deviation'].mean()\n",
    "\n",
    "avg_std_dev_dict = [avg_min_std_dev,\n",
    "                    avg_max_std_dev,\n",
    "                    avg_mean_std_dev,\n",
    "                    avg_median_std_dev,\n",
    "                    avg_std_std_dev,\n",
    "                    avg_1st_quart_std_dev,\n",
    "                    avg_3rd_quart_std_dev]\n",
    "\n",
    "# dataframe for average standard devs\n",
    "avg_std_devs_df = pd.DataFrame(avg_std_dev_dict, index=['min', 'max', 'mean', 'median', 'std', '1st quart', '3rd quart'], columns=['Average Standard Deviation'])\n",
    "# top 3 features with the highest standard deviation\n",
    "top_3_std_devs = avg_std_devs_df.nlargest(3, 'Average Standard Deviation')\n",
    "display(top_3_std_devs)\n",
    "print(\"Due to their high standard deviations, \", top_3_std_devs.index.values, \" have the highest variability in the dataset.\")\n",
    "print(\"This means meaning they are able to differentiate between the classes the best and represent separation between classes.\")\n",
    "print(\"Thus, they are the most important time-domain features.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "#### ISLR 3.7.4: I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. Y = β0 + β1X + β2X^2 + β3X^3 + ε.\n",
    "\n",
    "(a) Suppose that the true relationship between X and Y is linear, i.e. Y = β0 + β1X + ε. Consider the training residual sum of squares (RSS) for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "\n",
    "We would expect the **training residual sum of squares (RSS) for the cubic regression to be lower than that of the linear regression**, or at the very least, the same. The cubic regression model is more flexible than the linear regression model because it includes more terms (i.e. powers of X), meaning it can capture more complex relationships between X and Y. Since the cubic regression has more parameters, it can always fit the data as well or better than the linear model on the training set, even if the true relationship is linear (by setting polynomial parameters to 0). Therefore, the training RSS for the cubic regression will typically be lower than or equal to that of the linear regression.\n",
    "\n",
    "(b) Answer (a) using test rather than training RSS.\n",
    "\n",
    "When considering test residual sum of squares (RSS), we would expect the **linear regression to have a lower test RSS than the cubic regression if the true relationship between X and Y is linear**. If the true relationship is linear, the linear regression model will capture the true underlying pattern between X and Y. It will generalize better to new data since it is appropriately specified to reflect the true relationship. Due to the cubic model's flexibility and inclusion of polynomial terms, it might overfit, making it perform worse on new data\n",
    "\n",
    "(c) Suppose that the true relationship between X and Y is not linear, but we don’t know how far it is from linear. Consider the training RSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "\n",
    "Much like (a), because the cubic regression model is more flexible, it has the ability to represent a larger array of relationships between X and Y. By the same token, a linear model's nature might be too rigid, potentially leading to higher training RSS because it cannot account for the curvature or non-linear patterns in the data. Thus, we'd expect the **training RSS for the cubic regression would be lower than that for the linear regression** when the true relationship is not linear, due to the cubic model's greater flexibility in capturing non-linear patterns in the data.\n",
    "\n",
    "(d) Answer (c) using test rather than training RSS.\n",
    "\n",
    "When considering the test RSS, there are 2 cases to consider: the true relationship being only slightly non-linear, or the true relationship being significantly non-linear. In the former, the linear model may perform reasonably well, even though it’s not perfectly aligned with the true relationship. The cubic model, being more flexible, may overfit the training data and perform worse on test data due to capturing noise or random fluctuations. Thus, we could expect the linear model to have a lower test RSS. In the latter case, although the cubic model may still risk overfitting the training data, its increased flexibility will likely allow it to generalize better to the non-linear pattern in the test data, compared to the linear model. However, since we don't know how far the model is from linear, we'd have to say that **there's not enough information to tell which model would be better.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Citations  \n",
    "[#1 - Bootstrap Tutorial](https://towardsdatascience.com/calculating-confidence-interval-with-bootstrapping-872c657c058d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
